---
title: "Primary analysis of nuclei ATAC-seq"
author: "Evangelyn Sim"
date: "2/19/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




## Introduction

Following sequencing and obtaining .fastq.gz file, the first step is to perform trimming and mapping of the sequencing data to generate bam files. All these steps were performed using bash code. 

Bam files were then used for removal of duplicated and low quality (<Q30) reads and subsequently subjected to read counting to generate a count matrix.

Mouse AAV6:lacZ-shRNA or AAV6:Yap-shRNA bulk nuclei ATAC-seq were performed using paired-end sequencing method and below are the scripts for primary processing of paired-end sequencing read.


### Used libraries and functions

* skewer/0.2.2
* bwa/0.7.17
* samtools/1.8
* parallel
* subread/1.5.0
* bedtools/2.27.1
* macs14
* bedops/2.4.20


# 1. Basic processing of all samples

### Trimming of sequencing read

    #!/bin/bash

    # function to run skewer quality trimming
    runskew(){
    FQZ1=$1
    FQZ2=`echo $FQZ1 | sed 's/_R1.fastq.gz/_R2.fastq.gz/'`
    skewer -t 8 -q 20 $FQZ1 $FQZ2
    }
    export -f runskew

    # actually run skewer
    parallel -j3 runskew ::: *_R1.fastq.gz


### Mapping of Skewer trimmed .fastq to mouse reference genome using BWA

    runbwamempe() {
    FQ1=$1
    FQ2=`echo $FQ1 | sed 's/R1.fastq-trimmed-pair1.fastq/R1.fastq-trimmed-pair2.fastq/'`
    BASE=`echo $FQ1 | sed 's/_R1.fastq-trimmed-pair1.fastq//'`

    REF=/group/card2/Evangelyn_Sim/Collaboration_Kev_UoM/Sequencing_ATAC_RNA/refgenome/Mus_musculus.GRCm38.dna_sm.primary_assembly.fa

    bwa mem -t 20 $REF $FQ1 $FQ2 \
    | samtools view -uSh - \
    | samtools sort -@10 -o ${BASE}.sort.bam
    samtools index ${BASE}.sort.bam

    samtools flagstat ${BASE}.sort.bam > ${BASE}.sort.bam.stats
    }
    export -f runbwamempe


    # actually run bwa pe
    ls *_R1.fastq-trimmed-pair1.fastq | parallel -u -j4 runbwamempe {}



### Remove duplicated reads

    #!/bin/bash

    nodup(){
    BAM=$1
    OUT=`echo $BAM | sed 's/.bam/_nodup.bam/'`
    samtools rmdup $BAM $OUT
    }
    export -f nodup
    parallel nodup ::: `ls *bam | grep -v dup`




# 2. Peaks

### Peak call of individual sample

    #!/bin/bash
    BAMS='*bam'
    BASENAME=humanATAC
    PEAKBED=${BASENAME}_peaks.bed
    PEAKSAF=${BASENAME}_peaks.saf
    OUT=${BASENAME}_pks.txt
    MX=${BASENAME}_pks_se.mx

    PATH=$PATH:/usr/local/installed/macs/1.4.2-1/python-2.7.11/.//bin/

    ls $BAMS | parallel macs14 -t {} -n {}_macs

    done

    exit


### Curate peaks that exist in more than 2 or 3 samples to form a peak set


    for BED in *peaks.bed ; do
     awk '{OFS="\t"} {if ($2<1) print $1,1,$3 ; else print $0 }' $BED | awk 'NF=="5"'> tmp
     mv tmp $BED
    done

    rm humanATAC_peaks_cov*.bed
    for COV in 2 3 ; do
      bedtools multiinter -i *_macs_peaks.bed \
     | cut -f-4 | awk -v C=$COV '$4>=C && NF==4' \
     | bedtools merge -i - > mouseATAC_peaks_cov${COV}.bed
    done

    exit


### Count individual sample to the curated peak set

```{bash}
#!/bin/bash

for BED in mouseATAC*bed ; do

  SAF=$BED.saf
  OUT=$SAF.pe.mx
  awk '{OFS="\t"} {print "PK"NR"_"$1":"$2"-"$3,$1,$2,$3,"+"}' $BED > $SAF
  ( featureCounts -p -Q 10 -T 20 -s 0 -a $SAF -F SAF -o $OUT *bam
  sed 1d $OUT | cut -f1,7- > tmp ; mv tmp $OUT ) &

done

```

### Tidy peak count matrix

```{bash}
#!/bin/bash

for MX in `ls *mx` ; do
   cat $MX | sed 's/-ATAC.sort_nodup.bam//g' > $MX.fix
done
wait


```


### Filter out low counts genes from peak count matrix

Filtering out low counts genes by running the following filter.sh as 

  bash filter.sh mouseATAC_peaks_cov2.bed.saf.pe.mx.fix

  filter.sh

    head -1 $1 > ${1}_filt
    awk '{
      min = max = sum = $2;       # Initialize to the first value (2nd field)
      sum2 = $2 * $2              # Running sum of squares
      for (n=3; n <= NF; n++) {   # Process each value on the line
        if ($n < min) min = $n    # Current minimum
        if ($n > max) max = $n    # Current maximum
        sum += $n;                # Running sum of values
        sum2 += $n * $n           # Running sum of squares
      }
      print sum/(NF-1) ;
    }' $1 > avg
    paste avg $1 | awk '$1 >= 10' | cut -f2- | tr ' ' '\t' >> ${1}_filt
    rm avg

